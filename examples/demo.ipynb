{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install llama3 locally via Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See \"Using Llama 3 With Ollama\" section of https://www.datacamp.com/tutorial/run-llama-3-locally\n",
    "\n",
    "To summarize:\n",
    "- install `ollama`\n",
    "- run `ollama run llama3`\n",
    "    - the first time this step is performed, the model will be locally downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install other deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running llama locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\", request_timeout=120.0)\n",
    "resp = llm.complete(\"Who is Paul Graham?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2039k  100 2039k    0     0  8429k      0 --:--:-- --:--:-- --:--:-- 8532k\n"
     ]
    }
   ],
   "source": [
    "!curl https://arxiv.org/pdf/2212.08073 -o 2212.08073.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constitutional AI: Harmlessness from AI Feedback\n",
      "Yuntao Baiâˆ—, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion,\n",
      "Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,\n",
      "Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain,\n",
      "Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller,\n",
      "Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt,\n",
      "Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Merc\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"2212.08073.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "text = \"\".join(page.extract_text() for page in reader.pages)\n",
    "print(text[:500])\n",
    "\n",
    "\n",
    "prompt = f\"\"\"Here is an academic paper: <paper>{text}</paper>\n",
    "\n",
    "Please do the following:\n",
    "1. Summarize the abstract at a kindergarten reading level. (In <kindergarten_abstract> tags.)\n",
    "2. Write the Methods section as a recipe from the Moosewood Cookbook. (In <moosewood_methods> tags.)\n",
    "3. Compose a short poem epistolizing the results in the style of Homer. (In <homer_results> tags.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are my attempts at fulfilling your requests:\n",
      "\n",
      "**Summary of Abstract**\n",
      "\n",
      "<kindergarten_abstract>\n",
      "Constitutional AI is important because it helps people be kind and honest when talking to each other on computers. The paper talks about how some humans can say mean things, but the AI should not say those things. It's like being a good friend and helping someone feel better.</kindergarten_abstract>\n",
      "\n",
      "**Methods Section as a Recipe**\n",
      "\n",
      "<moosewood_methods>\n",
      "Constitutional AI Feedback Model\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 1 cup of human conversations\n",
      "* 1/2 cup of principles for harmless language (e.g., no judgments, be respectful)\n",
      "* 1 tablespoon of careful thinking\n",
      "* 1 teaspoon of sensitivity to harmful content\n",
      "* 1/4 teaspoon of honesty and helpfulness\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your computer's language processing abilities.\n",
      "2. Combine human conversations with the principles for harmless language in a large mixing bowl.\n",
      "3. Add carefully thought-out responses to create a harmonious blend of helpful and honest language.\n",
      "4. Stir in sensitivity to harmful content, ensuring that all responses are respectful and considerate.\n",
      "5. Serve with a side of honesty and helpfulness, guaranteeing that your AI model is both kind and effective.\n",
      "\n",
      "</moosewood_methods>\n",
      "\n",
      "**Short Poem Epistolizing the Results (in the style of Homer)**\n",
      "\n",
      "<homer_results>\n",
      "O, ye seekers of truth and wisdom's light,\n",
      "Hear now the tale of Constitutional AI's might.\n",
      "In digital realms, where words can sting or soothe,\n",
      "This model shines, a beacon of honest youth.\n",
      "\n",
      "With careful thought and principles in hand,\n",
      "It crafts responses that heal and understand.\n",
      "No mean-spirited words shall leave its tongue,\n",
      "For kindness and respect are its guiding song.\n",
      "\n",
      "Through trials of toxic language's fire,\n",
      "It stands unbroken, with helpfulness as its dire.\n",
      "And when the darkness of harmlessness falls,\n",
      "It shines forth bright, a guiding star that calls.\n",
      "\n",
      "Thus let this model be thy shining guide,\n",
      "In digital realms, where truth and wisdom reside.</homer_results>\n",
      "\n",
      "Please note that my poem is an interpretation of the results in the style of Homer, but it may not perfectly capture the nuances of his original work.\n"
     ]
    }
   ],
   "source": [
    "resp = llm.complete(prompt)\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
